# Analysis and Evaluation of Grad-CAM Explanations
Final Project for DD2412 Course (Deep Learning, Advanced), KTH

The scope of this project was to reproduce the findings of [Grad-CAM](https://arxiv.org/abs/1610.02391), a deep visualization technique suitable to any CNN. We performed the following tasks:

1. Evaluated Grad-CAM on the Weakly Supervised Localisation Task (ILSVRC15 validation set), in which the agent aims to localise the object (via a bounding box) without being explicitly trained to do so, based solely on the visualization.
1. Compute Pointing Game Accuracy and Recall (ILSVRC15 validation set).
1. Compare Grad-CAM, Guided Grad-CAM and Guided Backpropagation with [occlusion maps](https://arxiv.org/pdf/1511.06457.pdf).
1. Reproduce and analyze a User study to compare the thetrustworthiness of Guided Grad-CAM and Guided Backpropagation using VGG-16 and AlexNet, leveraging the fact that the former is known to be more accurate.
1. Compare Grad-CAM with [Grad-CAM++](https://arxiv.org/abs/1710.11063), Integrated Gradients and SHAP medical data.
1. Propose a novel experiment for evaluating Grad-CAM's [sensitivity](https://arxiv.org/abs/1703.01365).
1. Compare Grad-CAM with Integrated Gradients and SHAP in regards to [contrastivity and fidelity](https://openaccess.thecvf.com/content_CVPR_2019/papers/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.pdf)

## Task 1

## Task 2

## Task 3

## Task 4

## Task 5

## Task 6

## Task 7
